{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c301f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fecb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('../data/kaggle_resume_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd996b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('../data/website_resumes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253f60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('../data/2480resumes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91743297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\r',\n",
       " 'GLENN WHITE\\r',\n",
       " 'Phone - 415-***-****\\r',\n",
       " 'Email - adn9fn@r.postjobfree.com\\r',\n",
       " '\\r',\n",
       " 'PROFILE SUMMARY\\r',\n",
       " '\\r',\n",
       " '•8+ Years Android Application Development.\\r',\n",
       " '•5 apps published on Google Play Store.\\r',\n",
       " '•2 apps developed in Alpha phase.\\r',\n",
       " '•1 app worked on for internal use.\\r',\n",
       " '•Self-motivated and proactive Android Mobile Application Developer experienced working with different multi-disciplinary test-driven development (TDD) Agile teams on small to large mobile app projects.\\r',\n",
       " '•Demonstrated ability to work and communicate effectively with other mobile engineers, device firmware engineers, technical leads, and project managers on teams applying Agile/Scrum methodologies.\\r',\n",
       " '•Solid understanding of project and software development lifecycles and all the steps involved in moving an app development through to deployment on the Google App Store.\\r',\n",
       " '•Applied various architecture and design patterns, including Singleton, MVP, REST, MVVP (Model, View, ViewModel), Dependency Injection (DI), and Model-View-Controller (MVC).\\r',\n",
       " '•Worked with various integrated development environments (IDE)/frameworks, including Dagger2, Bluetooth, Android Studio, Eclipse, Android Annotations, Robotium test framework, Espresso test framework, SpongyCastle cipher suites, Jenkins, JUnit unit testing, and Visual Studio App Center.\\r',\n",
       " '•Experience covers back-end to front-end development and includes building new functions/features and modifying existing functions/features.\\r',\n",
       " '•Worked with the latest Android development technologies, including the Kotlin programming language.\\r',\n",
       " '•Skilled Java programmer.\\r',\n",
       " '•Skill applying frameworks such as RxKotlin, RxJava, RxAndroid, RxBluetooth, etc.\\r',\n",
       " '•Current with Android releases and differences in Android versions.\\r',\n",
       " '\\r',\n",
       " 'SKILLS\\r',\n",
       " '\\r',\n",
       " 'ARCHITECTURE ~ UI/UX ~ INTERFACE ~ FIREBASE ~ PUSH NOTIFICATIONS ~ KOTLIN ~ REACTIVE ~ PROGRAMMING LOCAL DATABASE ~ JAVA ~ MULTITHREADING ~ VERSION CONTROL ~ CODE REVIEWS ~ ANDROID JETPACK ~ GOOGLE MAPS API ~ LOADERS ~ RXJAVA ~ JOB SCHEDULER ASYNCTASK ~ MATERIAL DESIGN ~ RECYCLER VIEW ~ WI-FI WEB SOCKET ~ FABRIC ~ FIREBASE ANALYTICS ~ TIMBER ~ RXKOTLIN ~ OKIO ~ JENKINS ~ PROFILERS ~ AIRSHIP ~ FLOW API ~ MULTITHREADING ~ ESPRESSO ~ JUNIT ~ MOCKITO ~ LEAK CANARY ~ RESTFUL WEB SERVICES ~ BITBUCKET ~ GITHUB ~ DEPENDENCY INJECTION ~ CUSTOM VIEW ~ MVP ~ MVVM ~ BLE ~ LIVEDATA ~ VIEWMODEL ~ BUILDER ~ ADAPTER ~ FACTORY ~ ASSISTEDINJECTION ~ HP QUALITY CENTER ~JENKINS ~ JIRA ~ SLACK ~ ANDROID STUDIO ~ VISUAL STUDIO ~ ECLIPSE ~ ASP.NET ~\\r',\n",
       " '\\r',\n",
       " 'WORK HISTORY\\r',\n",
       " '\\r',\n",
       " 'Sr. Android Application Developer\\r',\n",
       " 'Oct 21 – Present\\r',\n",
       " 'Woonsocket, RI\\r',\n",
       " '\\r',\n",
       " 'CVS\\r',\n",
       " '(App is internal)\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Assigned to an Agile dev team to help maintain and update the company’s internal applications that are deployed on Zebra devices and Samsung tablets that are used in store.\\r',\n",
       " '•Updated their internal browser to display weekly ads as a shortcut on Zebra devices.\\r',\n",
       " '•Created the foundation for receiving key performance indicators (KPIs) for analytics.\\r',\n",
       " '•Supported User Acceptance Testing (UAT) team.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Worked in Android Studio with coding in Java and Kotlin using a MVVM architecture.\\r',\n",
       " '•Performed phased Java to Kotlin migration,\\r',\n",
       " '•Refactored code with extension functions, sealed classes, null safety checks, and data classes.\\r',\n",
       " '•Started migration of their Spark application to use Chrome Custom tabs.\\r',\n",
       " '•Developed Weekly ad update for client’s internal browser.\\r',\n",
       " '•Helped UAT team install new Toshiba APK for testing.\\r',\n",
       " '•Side loaded new APKs for UATs.\\r',\n",
       " '•Conducted peer code reviews to ensure quality code consistency.\\r',\n",
       " '•Tested internal web browser to ensure that the web page was appearing well.\\r',\n",
       " '•Presented technical reviews for new code.\\r',\n",
       " '•Debugged codebase with Splunk dashboards and Firebase Crash.\\r',\n",
       " '•Implemented unit testing and integration testing with JUnit, Mockito, and Espresso.\\r',\n",
       " '•Configured multithreads to receive and update calls from web server (Service and Broadcast Receiver).\\r',\n",
       " '\\r',\n",
       " 'Sr. Android App Developer\\r',\n",
       " 'Mar 21 – Oct 21\\r',\n",
       " 'Columbus, OH\\r',\n",
       " '\\r',\n",
       " 'Gap: Self-Checkout App\\r',\n",
       " '(App is still in Alpha)\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Worked on an Agile team mandated to build the Self-Checkout app from scratch to allow users to make purchases in store by only using the app on their device. This app also works as an instant app as well as part of the Gap’s larger app ecosystem.\\r',\n",
       " '•Led team huddles and daily stand ups.\\r',\n",
       " '•Mentored junior developers.\\r',\n",
       " '•Helped new team members on board.\\r',\n",
       " '•Led tech demos of the code base in action to VIPs within the organization.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Built the app on a MVVM – Clean Architecture.\\r',\n",
       " '•Worked in Android Studio with coding in Kotlin.\\r',\n",
       " '•Migrated code base to a module for integration to a larger code base.\\r',\n",
       " '•Applied RxKotlin in conjunction with RxAndroid and RxBinding libraries to make app multithreaded and perform synchronous operations.\\r',\n",
       " '•Implemented Android Architecture lifecycle aware components and using LiveData to build data objects that notify views when the underlying database changes.\\r',\n",
       " '•Designed/developed app using API/SDK and business embedded logic to achieve mobile app’s desired functionality.\\r',\n",
       " '•Used Data Binding for decoupled UI updating.\\r',\n",
       " '•Used Bottom sheet fragments for better data presentation.\\r',\n",
       " '•Created instant app experience (includes both the basic and enhanced instant app experience).\\r',\n",
       " '•Created session Tokens for Logged in, Guest, and Anonymous sign in.\\r',\n",
       " '•Used Room library for database management.\\r',\n",
       " '•Applied Google Vision for credit card scanning.\\r',\n",
       " '•Utilized Zixing library for barcode scanning.\\r',\n",
       " '•Used Proguard and R8 for shrinking the code base.\\r',\n",
       " '•Conducted regression testing for the release of the app using Robotium.\\r',\n",
       " '\\r',\n",
       " 'Sr. Android Developer\\r',\n",
       " 'Oct 20 – Mar 21\\r',\n",
       " 'Remote\\r',\n",
       " '\\r',\n",
       " 'Walmart Labs: Project Glass\\r',\n",
       " '(App is still in Alpha)\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Mentored junior developers, assisted in reading code base, performed code reviews, etc.\\r',\n",
       " '•Worked in an Agile team and played Scrum Master (daily standups, weekly planning meetings).\\r',\n",
       " '•Led discussions and contributed to technical decisions, striving for clean architecture.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Designed App Architecture, select necessary tools, frameworks, and patterns with Android JetPack Architectural components (LiveData, ViewModel, Room).\\r',\n",
       " '•Integrated Retrofit for network call handling.\\r',\n",
       " '•Created analytic BLE beacons for tracking information.\\r',\n",
       " '•Pulled server data using REST API, using Retrofit, OkHTTP and RxJava(RxAndroid) networking libraries.\\r',\n",
       " '•Used Kotlin to update the code base to bring it more in line with the rest of the various modules.\\r',\n",
       " '•Created functional test to ensure that new code is working properly and as intended.\\r',\n",
       " '•Collaborated with external clients to include Branch SDK for mobile conversion, retention, and engagement through deep linking and user routing.\\r',\n",
       " '•Use Mockito API for Capturing the arguments, wrapping java objects with spy and verify the calls on the mock objects.\\r',\n",
       " '•Refactored code base to implement dependency injection strategy using Dagger library.\\r',\n",
       " '•Created several components and factory interfaces to isolate app components into modular fashion.\\r',\n",
       " '•Implemented background services to keep track of BLE connectivity and resolve issues with Android Oreo background limitations.\\r',\n",
       " '•Coded schedulable jobs through WorkManager API.\\r',\n",
       " '•Performed bug fixes on existing code and took part in code reviews.\\r',\n",
       " '•Participated in sprint retrospective, where I gave suggestions on how to improve the worflow.\\r',\n",
       " '•Defined migrations strategy with the implementation of Room database to remove previous SqliteOpen helper implementation.\\r',\n",
       " '\\r',\n",
       " 'Sr. Android Developer\\r',\n",
       " 'Oct 19 – Sept 20\\r',\n",
       " 'San Francisco CA\\r',\n",
       " '\\r',\n",
       " 'Everlance: Free Mileage Log\\r',\n",
       " 'https://play.google.com/store/apps/details?id=com.everlance\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Collaborated with the server-side developers to design APIs specifically for the Android application.\\r',\n",
       " '•Work in a multi-disciplinary team in London and alongside dev peers throughout US within an agile team (daily standups, weekly planning meetings).\\r',\n",
       " '•Lead discussions and contributing to technical decisions, striving for clean architecture.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Designed App Architecture, select necessary tools, frameworks and patterns with Android JetPack Architectural components (LiveData, ViewModel, Room)\\r',\n",
       " '•Worked with Android Beacon Library API to request ranging update from one or more beacons at a frequency of approximately 1Hz.\\r',\n",
       " '•Exported data to CSV or PDF using Android PdfViewer and FastCRV external library.\\r',\n",
       " '•Saved and backup a GPS \"mileage receipt\" for each trip using FireBase Cloud Backend and Realtime database services.\\r',\n",
       " '•Upload paper receipts of meals, supplies, and other expenses with background threads using JobSchedulers and JobIntentServices to MongoDB backend.\\r',\n",
       " '•Consumed Milage API, Accounts details API using Retrofit, okhttp and RxJava(RxAndroid) networking libraries.\\r',\n",
       " '•Migrate and develop new products features using Kotlin programming language features and Android KTX.\\r',\n",
       " '•Upgraded payments systems within the app by incorporating Stripe SDK to accept and manage card payments.\\r',\n",
       " '•Collaborated with external clients to include Branch SDK for mobile conversion, retention, and engagement through deep linking and user routing.\\r',\n",
       " '•Use Mockito API for Capturing the arguments, wrapping java objects with spy and verify the calls on the mock objects.\\r',\n",
       " '•Refactored code base to implement dependency injection strategy using Dagger library.\\r',\n",
       " '•Created several components and factory interfaces to isolate app components into modular fashion.\\r',\n",
       " '•Implemented background services to keep track of BLE connectivity and resolve issues with Android Oreo background limitations.\\r',\n",
       " '•Coded schedulable jobs through WorkManager Api to have routines for backup information from Mileage Website entries.\\r',\n",
       " '•Contributed with proper documentation and KT documents to ease onboarding process for new developers.\\r',\n",
       " '•Defined migrations strategy with the implementation of Room database to remove previous SqliteOpen helper implementation.\\r',\n",
       " '\\r',\n",
       " 'Sr. Android Developer\\r',\n",
       " 'Aug 18 – Sep 19\\r',\n",
       " 'Atlanta, GA\\r',\n",
       " '\\r',\n",
       " 'Mercedes me (USA)\\r',\n",
       " 'https://play.google.com/store/apps/details?id=com.mbusa.mercedesme.android\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Ensured new and existing applications met Mercedes requirements.\\r',\n",
       " '•Code reviewed peer’s development.\\r',\n",
       " '•Worked with Designers and Product Managers to agree product definitions.\\r',\n",
       " '•Coded, debugged and united test systems per requirements and technical design.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Coded in existing MVVM architecture using Data Binding Library to bind UI components in the layouts to data sources.\\r',\n",
       " '•Created Repository layer and abstracted monolithic ViewModel into view-case scenario.\\r',\n",
       " '•Performed Offline database synchronization with Realm Database to display the latest news from Mercedes-Benz, View manuals and how-to videos.\\r',\n",
       " \"•Scheduled payments with Mercedes-Benz Financial Services using Google Pay API to request any credit or debit card stored in customer's Google Account.\\r\",\n",
       " '•Posted and update account and contact information with Backend API using Retrofit Form-Encoding and perform secure network traffic transmission.\\r',\n",
       " '•Worked with Android NDK and use ReLinker library to load native libraries asynchronously.\\r',\n",
       " '•Upgraded Splunk MINT SDK to collect crash, performance and usage data for your app and send it to our Cloud servers.\\r',\n",
       " '•Worked alongside senior developer to use AltBeacon library to interact and get notifications when one or more beacons appear or disappear.\\r',\n",
       " '•Addressed many of the development and performance issues that plagued reflection-based solutions using Dagger2 injection library.\\r',\n",
       " '•Communicated with Amazon Web Services (AWS) for secure cloud services platform, database storage and content delivery.\\r',\n",
       " '\\r',\n",
       " 'Android Specialist\\r',\n",
       " 'May17 – Aug 18\\r',\n",
       " 'San Francisco, CA\\r',\n",
       " '\\r',\n",
       " 'DoorDash – Food Delivery\\r',\n",
       " 'https://play.google.com/store/apps/details?id=com.dd.doordash\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Worked with other developers to write software based on backlog items.\\r',\n",
       " '•Worked with testers to ensure they are engaged and ready to test the software at the right time in the development cycle.\\r',\n",
       " '•Supported, refactored and enhanced existing production systems.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Organized business logic, workflows, processes, rules in Domain layer and communicated with data/ presentation layer in MVP architecture.\\r',\n",
       " '•Integrated OAuth2 authentication with Identity Server.\\r',\n",
       " '•Enhanced the module that communicates with the Java WebServices with Volley library.\\r',\n",
       " '•Collected customer data and send it to your tools for mobile analytics, marketing automation, and raw data access with SQL using Segment SDK.\\r',\n",
       " '•Replaced Samsung Pay with card.io library for credit card scanning and BrainTree SDK.\\r',\n",
       " '•Used Git flow for code integration, Jenkins for continuous integration and JIRA for bug tracking.\\r',\n",
       " '•Worked on `Schedule Deliveries’ and `Real Time tracking’ acceptance criteria’s in TDD manner.\\r',\n",
       " '•Wrote automated UI test cases using Espresso and functional integration testing using Robolectric API.\\r',\n",
       " '•Performed additional beta testing using Google Cloud testing mechanism.\\r',\n",
       " '•Encrypted card details in Android Keystore system to store cryptographic keys in a container to make it more difficult to extract from the device.\\r',\n",
       " '\\r',\n",
       " 'Native Android Developer\\r',\n",
       " 'June 15 – May 17\\r',\n",
       " 'Dublin, OH\\r',\n",
       " '\\r',\n",
       " 'Patient Medical Records & Appointments for Doctors\\r',\n",
       " 'https://play.google.com/store/apps/details?id=us.drpad.drpadapp\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•Helped define development environment and communicate the best development practices within the organization (i.e. code reviews, testing, etc.)\\r',\n",
       " '•Worked closely with other teams (Stakeholders, Product and UX) to drive product development in an iterative and agile way.\\r',\n",
       " '•Participated in the relevant scrum events; planning and estimation, daily scrums, sprint reviews, and retrospectives.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " \"•Defined business rules for data manipulation and then processed the user's data with the help of Model and passed the results back to the View in MVC architecture.\\r\",\n",
       " \"•Created and updated patient's appointments, visit history, and medical records locally using Realm database library.\\r\",\n",
       " '•Worked with Calendar API to send SMS and/or email appointment reminder.\\r',\n",
       " '•Automated sync to secure AWS cloud at a specific time (Save data to cloud automatically) using IntentServices and AlarmManager API.\\r',\n",
       " '•Created automatic routines scheduling network requests and transparent disk and memory response caching with standard HTTP with Volley library.\\r',\n",
       " '•Pair-programmed to work on Google CData Client library for HTTP transport, error handling, authentication, JSON parsing, media download/upload, and batching.\\r',\n",
       " '•Incorporated VuDroid library to enable PDF functionality within the app.\\r',\n",
       " '•Created Custom view circular ImageView to display profile images, material Dialogs, graphs, tabs and custom progress bars.\\r',\n",
       " '•Worked with Behavior Driven Development frameworks such as Cucumber.\\r',\n",
       " '\\r',\n",
       " 'Jr. Programmer\\r',\n",
       " 'Sep 13 – May 15\\r',\n",
       " 'Sterling, VA\\r',\n",
       " 'AOL – News, Mail & Video\\r',\n",
       " 'https://play.google.com/store/apps/details?id=com.aol.mobile.aolapp\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " \"•Collaborated as a member of the team undertaking the shared commitment towards completion of the team's sprint goals.\\r\",\n",
       " \"•Accepted joint responsible with the team for converting the Product backlog into 'Done' potentially releasable increments.\\r\",\n",
       " '•Worked within an Agile team to deliver across the entire product life cycle – concept, design, build (code), deploy, test, release, and maintain unit, functional, and performance test automation.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Worked with NineOldAndroids library to include animating rotation, translation, alpha and scale.\\r',\n",
       " '•Implemented disk-based LRU cache which specifically targets Android compatibility for accessing filesystem.\\r',\n",
       " '•Optimized UI for different android versions and devices using Fragments.\\r',\n",
       " '•Parsed JSON data using HTTP client (GET, POST, DELETE, PUT) Volley library and displayed in a listview following view holder pattern to display latest news and articles.\\r',\n",
       " '•Upgraded Twitter SDK and Facebook SDK to share articles and videos.\\r',\n",
       " '•Performed XML DOM parsing to weather information according to current location of the user.\\r',\n",
       " '•Configured and send Notifications around breaking news and important emails using GCM with UrbanAirShip client.\\r',\n",
       " '•Implemented data persistence using SQLite for caching data in the app device.\\r',\n",
       " '\\r',\n",
       " 'Associate Software Engineer\\r',\n",
       " 'May 10 to Sept 13\\r',\n",
       " 'Columbus, OH\\r',\n",
       " '\\r',\n",
       " 'ACCENTURE\\r',\n",
       " '\\r',\n",
       " 'Responsibilities:\\r',\n",
       " '\\r',\n",
       " '•This was a sub-contracted role with JP Morgan Chase.\\r',\n",
       " '•Under constant supervision, collaborated with multiple teams under JP Morgan Chase development team.\\r',\n",
       " '•Participated in several Code-Labs and Courses covering technical discussions and increase code quality.\\r',\n",
       " '\\r',\n",
       " 'Tech Contributions:\\r',\n",
       " '\\r',\n",
       " '•Successfully assisted multiple teams to build and deploy to both test and live servers.\\r',\n",
       " '•Utilized version control software such as GitHub and Jenkins to deploy and monitor software releases.\\r',\n",
       " '•Contributed to created multiple Jenkin pipelines to speed up build process.\\r',\n",
       " '•Created small fixes to help software compile and deploy to large enterprise servers.\\r',\n",
       " '•Effectively tested new software for bugs and defects for the JP Morgan consumer banking branch.\\r',\n",
       " '•Including Microsoft Excel and HP Quality Center to both manage defects as well as creating test scripts.\\r',\n",
       " '•Created several test cases using tools like Cucumber, Mockito and jUnit.\\r',\n",
       " '•Worked closely with product owners and business analyst to ensure that any new functionality both worked but also did not break any existing functionality.\\r',\n",
       " '•Collaborated with QA engineers to elaborate uses cases and implement pyramid test.\\r',\n",
       " '•Applied happy path along with black box white box strategy to ensure code quality in multiple assignations.\\r',\n",
       " '•Provided support to various software teams in migrating software access to a central access team.\\r',\n",
       " '\\r',\n",
       " 'EDUCATION\\r',\n",
       " 'DeVry University, Columbus, OH\\r',\n",
       " 'Bachelor of Science in Computer Engineering Technology\\r',\n",
       " '\\r',\n",
       " '']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['resume'][0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19d3ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('../test/traindata.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa97841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91c8a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines=[]\n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content']\n",
    "            entities = []\n",
    "            for annotation in data['annotation']:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
    "\n",
    "\n",
    "            training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e1c5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53a2ff9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.18'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ae62bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN',\n",
       " {'entities': [(1155, 1199, 'Email Address'),\n",
       "   (743, 1141, 'Skills'),\n",
       "   (729, 733, 'Graduation Year'),\n",
       "   (675, 703, 'College Name'),\n",
       "   (631, 673, 'Degree'),\n",
       "   (625, 630, 'Graduation Year'),\n",
       "   (614, 623, 'College Name'),\n",
       "   (606, 612, 'Degree'),\n",
       "   (104, 148, 'Email Address'),\n",
       "   (62, 68, 'Location'),\n",
       "   (0, 14, 'Name')]})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57af893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "Statring iteration 0\n",
      "{'ner': 1424.2040737901666}\n",
      "Statring iteration 1\n",
      "{'ner': 687.7199811311953}\n",
      "Statring iteration 2\n",
      "{'ner': 486.5370940342219}\n",
      "Statring iteration 3\n",
      "{'ner': 420.368192069885}\n",
      "Statring iteration 4\n",
      "{'ner': 359.82867820645635}\n",
      "Statring iteration 5\n",
      "{'ner': 316.63764802408326}\n",
      "Statring iteration 6\n",
      "{'ner': 270.9706268676556}\n",
      "Statring iteration 7\n",
      "{'ner': 220.03902189374904}\n",
      "Statring iteration 8\n",
      "{'ner': 194.1730694216207}\n",
      "Statring iteration 9\n",
      "{'ner': 171.37609418082937}\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = convert_dataturks_to_spacy('../test/testdata.json')\n",
    "nlp = spacy.blank('en')  # create blank Language class\n",
    "# create the built-in pipeline components and add them to the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "\n",
    "\n",
    "# add labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "     for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])==0\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.2,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58852d0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[E002] Can't find factory for 'tok2vec'. This usually happens when spaCy calls `nlp.create_pipe` with a component name that's not built in - for example, when constructing the pipeline from a model's meta.json. If you're using a custom component, you can write to `Language.factories['tok2vec']` or remove it from the model meta and add it via `nlp.add_pipe` instead.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-868abf74e5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"../output/model-best\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"there was a flight named D16\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input sample text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ent\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjupyter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# display in Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pipeline_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, name, config)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE002\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[E002] Can't find factory for 'tok2vec'. This usually happens when spaCy calls `nlp.create_pipe` with a component name that's not built in - for example, when constructing the pipeline from a model's meta.json. If you're using a custom component, you can write to `Language.factories['tok2vec']` or remove it from the model meta and add it via `nlp.add_pipe` instead.\""
     ]
    }
   ],
   "source": [
    "nlp1 = spacy.load(r\"../output/model-best\") #load the best model\n",
    "doc = nlp1(\"there was a flight named D16\") # input sample text\n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
