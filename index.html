<!DOCTYPE html>
<html lang="en">

<head>
 <meta charset="UTF-8" />
 <meta name="viewport" content="width=device-width, initial-scale=1.0" />
 <meta http-equiv="X-UA-Compatible" content="ie=edge" />
 <title>DSC180B Capstone Project</title>
 <link href="https://fonts.googleapis.com/css?family=Montserrat|Paytone+One&display=swap" rel="stylesheet" />
 <link href="./styles/final_project.css" rel="stylesheet" />
 <script src="./scripts/main.js"></script>
</head>

<body>

 <div id="main">
  <h1 id="titlename">Resume Information Extraction with NER</h1>
  <p id="authorname"> Qiwen Zhang, Haibo Li, Judy Yang, Yufei Zhou</p >
  <hr style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">
  <br >
  <div>
    <h2>Introduction</h2>
    <p>Have you submitted resumes to tons of companies but failed to receive a single response? Have you been frustrated about job applications? Have you ever wondered why your resume is unable to get through the screening?</p>
    <p>As soon-to-be graduates, these questions often occur to us. There is no doubt that a resume is the most important stepping stone to secure a job. Therefore, we want to focus on creating an automatic resume summarizer, where we implement Named Entity Recognition models to automatically highlight information on the resume; this will help people compare them with the job description in order to create a more refined and targeted resume.</p>
  </div>
  <hr  style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">
  <div>
    <h2>Methodology & Approach</h2>

    <p>We use python’s <a href="https://spacy.io/usage/spacy-101"><b>spaCy</b></a> module for training the NER model. spaCy’s models are statistical and every “decision” they make is a prediction. The model is then shown the unlabelled text and will make a prediction. Because we know the correct answer, we can give the model feedback on its prediction in the form of an error gradient of the loss function that calculates the difference between the training example and the expected output. The greater the difference, the more significant the gradient and the updates to our model.</p>
    <div><img src="./images/methodology_1.png" width="1100px" height="200px"></div>
    <p>When training a model, we don’t just want it to memorize our examples — we want it to come up with a theory that can be generalized across other examples. In order to tune the accuracy, we process our training examples in batches, and experiment with minibatch sizes and dropout rates.</p>
    <p>Three models are trained to predict the named entity.</p>
    <h4>Submodels that are used in the training pipeline:</h4>
      <ul>
        <li><p><a href="https://spacy.io/api/architectures#Tok2Vec"><b>Token to vector model</b></a>: This model embed tokens into vectors that contain contextual information. It uses hash embedding to convert tokens to vectors which are context-independent and uses convolution with maxout activation function to learn context information.</p></li>
        <li><p><a href="https://spacy.io/api/architectures#TransformerModel"><b>RoBERTa fine tuned</b></a>: A transformer model that maps tokens into vectors with contextual information.</p></li>
        <li><p><a href="https://spacy.io/api/architectures#TransitionBasedParser"><b>Transition-based named entity recognition model</b></a>: It uses a transition-based parsing to predict the named entity using structure information.</p></li>
      </ul>
    <h4>Model Architecture:</h4>
      <ul>
        <li><p><b style=color:black>Baseline</b>: The baseline model includes a token to vector model and a transition-based named entity recognition model. </p></li>
        <li><p><b style=color:black>RoBERTa fine tuned</b>: Includes a roberta-base model and a transition-based named entity recognition model.</p></li>
        <li><p><a href="https://spacy.io/models/en#en_core_web_lg"><b>Spacy fine tuned</b></a>: Includes a pre-trained token to vector model by spacy and a transition-based named entity recognition model.</p></li>
      </ul>
  </div>
  <hr  style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">
  <h2>Results / Impact</h2>

  <div id="result"><img src="./images/result_1.png" width="600px" height="400px"></div>
  <p>Model performance(3 models): We compared the f1 score, precision, and recall of all our three models. In general, the spaCy fine-tuned model has the highest f1 and precision, while the RoBERTa fine-tuned models have the highest recall.
Our model performs surprisingly well on entity recognition especially on the “Education” section of each resume. It recognizes most of the important entities from the section with only a few left out.</p>
  <p> This can be explained by the fact that entities in the “Education” section are usually identified with relatively unique words, such as “Bachelor of”, “Master of”, “XXX College”, etc. Other entities are usually identified with ambiguous words. For example, “Skills” are especially hard for the model to pick out as they are hidden in larger paragraphs and contain grammatical variants.</p>
  <br>
  <div id="result"><img src="./images/output.png" width="450px" height="700px"></div>

  <hr  style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">
  <h2>Interactive Application Demo</h2>
  <h3>Try it out yourself with a pdf version of your current resume and secure your next job application</h3>
  <div>
  <a href="https://dsc180nerweb.herokuapp.com/"><button class ="button button2">Start Demo</button></a>
  </div>

  <br>

  <hr  style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">
  <h2>Conlusion</h2>
  <h4>Reasons about different model performance</h4>
  <ul>
    <li><p>spaCy and RoBERTa both used pretrained models with more complex network and flexibility to handle named entity recognition tasks</p></li>
    <li><p>spaCy takes an object oriented approach, white it is not used in our project, spaCy can support over 50 languages. spaCy provides the fastest and most accurate syntactic analysis of any NLP library released to date. It also offers access to larger word vectors that are easier to customize.</p></li>
  </ul>
  <h4>Drawbacks</h4>
  <ul>
    <li><p>Labeling does not follow a common standard</li>
    <li><p>Training set is too small, but may show our method can be quite robust with larger training set</p></li>
    <li><p>Sources of sample resumes are not diverse, many resumes may have similar patterns. The types of resumes may not be diverse enough as well.</p></li>
  </ul>
  <h4>How to improve in the future</h4>
  <ul>
    <li><p>Using more and more diverse types of resumes</li>
    <li><p>Resume labeling follows a common standard</li>
    <li><p>Making use of different pretrained models and fine-tuning the models with different hyperparameters as an attempt to improve the model performance</p></li>
  </ul>
  <hr  style="height:2px;border-width:0;color:rgb(252, 177, 177);background-color:rgb(248, 184, 184)">

</div>
</body>
</html>
